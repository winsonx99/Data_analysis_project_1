{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Web crawling code"
      ],
      "metadata": {
        "id": "jpCIlpX1RIL0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnfaAA71rPUi"
      },
      "outputs": [],
      "source": [
        "#pip install selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Panknshop\n"
      ],
      "metadata": {
        "id": "er3pgQtjRCdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parknshop web crawler\n",
        "\n",
        "import pandas as pd\n",
        "from selenium import webdriver # use webdriver\n",
        "from selenium.webdriver.common.by import By # different methods of locating data\n",
        "from selenium.webdriver.chrome.options import Options # options for selenium driver\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "\n",
        "def crawler(url):\n",
        "\n",
        "    driver = webdriver.Chrome() # create instance of selenium driver\n",
        "\n",
        "    try:\n",
        "        driver.get(url)\n",
        "    except:\n",
        "        print(\"url not found\")\n",
        "        exit\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "\n",
        "    # get the total number of products (shown on the web page)              XPath of no of product\n",
        "    total_no_of_product = driver.find_element(By.XPATH, \"/html/body/app-root/cx-storefront/main/cx-page-layout/cx-page-slot//pns-product-list/div[1]/div[1]\")\n",
        "    total_no_of_product = int(total_no_of_product.text.split(\" \")[0])       # get the total number of products (shown on the web page)\n",
        "    print('total_no_of_product : ', total_no_of_product)\n",
        "\n",
        "    # find product elements on website\n",
        "    products = driver.find_elements(By.XPATH, \"//html/body/app-root/cx-storefront/main/cx-page-layout/cx-page-slot//pns-product-list/div[2]/div/pns-product-tile\")\n",
        "    print(len(products))        # print number of product elements found\n",
        "\n",
        "    # create empty lists for dataframe\n",
        "    remark = []\n",
        "    name = []\n",
        "    capacity = []\n",
        "    selling_price = []\n",
        "    original_price = []\n",
        "    more_info = []\n",
        "    link = []\n",
        "\n",
        "    # create dictionary for dataframe\n",
        "    result_dict = {\n",
        "        \"remark\" : remark,\n",
        "        \"name\" : name,\n",
        "        \"capacity\" : capacity,\n",
        "        \"selling_price\" : selling_price,\n",
        "        \"original_price\" : original_price,\n",
        "        \"more_info\" : more_info,\n",
        "        \"link\" : link\n",
        "    }\n",
        "\n",
        "\n",
        "    index  = 0      # for checking process\n",
        "    while len(products) < total_no_of_product:\n",
        "\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")     # scroll to the bottom of the page, for showing more products\n",
        "        time.sleep(2)\n",
        "        #  find product elements on website\n",
        "        products = driver.find_elements(By.XPATH, \"//html/body/app-root/cx-storefront/main/cx-page-layout/cx-page-slot//pns-product-list/div[2]/div/pns-product-tile\")\n",
        "\n",
        "        print(f'{index} - {len(products)}')     # for checking process\n",
        "        index += 1      # for checking process\n",
        "\n",
        "\n",
        "    for product in products:        # for each product\n",
        "        # print(product.text.split(\"\\n\"))\n",
        "        # print(len(product.text.split(\"\\n\")))\n",
        "        # print('=' * 80)\n",
        "\n",
        "        product_info = product.text.split(\"\\n\")     # split the product information by \"/n\",  return a list\n",
        "        # the following if else condition is trying to input the product information into the correct column of the future dataframe\n",
        "        if len(product_info) == 4:\n",
        "            remark.append(None)\n",
        "            name.append(product_info[0])\n",
        "            capacity.append(product_info[1])\n",
        "            selling_price.append(product_info[2])\n",
        "            original_price.append(None)\n",
        "            more_info.append(product_info[-1])\n",
        "\n",
        "        elif len(product_info) == 5:\n",
        "            if \"$\" in product_info[-2] and \"$\" in product_info[-3]:\n",
        "                remark.append(None)\n",
        "                name.append(product_info[0])\n",
        "                capacity.append(product_info[1])\n",
        "                selling_price.append(product_info[2])\n",
        "                original_price.append(product_info[3])\n",
        "            else:\n",
        "                remark.append(product_info[0])\n",
        "                name.append(product_info[1])\n",
        "                capacity.append(product_info[2])\n",
        "                selling_price.append(product_info[3])\n",
        "                original_price.append(None)\n",
        "\n",
        "            more_info.append(product_info[-1])\n",
        "\n",
        "        elif len(product_info) == 6:\n",
        "            remark.append(product_info[0])\n",
        "            name.append(product_info[1])\n",
        "            capacity.append(product_info[2])\n",
        "            selling_price.append(product_info[3])\n",
        "            original_price.append(product_info[4])\n",
        "            more_info.append(product_info[-1])\n",
        "\n",
        "    # find all the product link on the page\n",
        "    product_link = driver.find_elements(By.XPATH, \"/html/body/app-root/cx-storefront/main/cx-page-layout/cx-page-slot//pns-product-list/div[2]/div/pns-product-tile//div/div[1]/div[2]/a\")\n",
        "    for product in product_link:\n",
        "        link.append(product.get_attribute('href'))      # get product link and put it into the list\n",
        "\n",
        "\n",
        "    driver.quit()       # close the browser\n",
        "\n",
        "    df = pd.DataFrame(result_dict)      # create dataframe\n",
        "\n",
        "    # use apply to remove \"$\" and \",\" from price by using data_cleaning function\n",
        "    # df['selling_price'] = df['selling_price'].apply(data_cleaning)\n",
        "    # df['original_price'] = df['original_price'].apply(data_cleaning)\n",
        "\n",
        "    return df       # return the dataframe\n",
        "\n",
        "\n",
        "# replace \"HK$\" & \",\" of str price, return float\n",
        "\"\"\"\n",
        "def data_cleaning(n):\n",
        "    if type(n) == str:\n",
        "        n = n.replace(\"$\", \"\")\n",
        "        n = n.replace(\",\", \"\")\n",
        "        n = float(n)\n",
        "    return n\n",
        " \"\"\"\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = \"https://www.pns.hk/zh-hk/%E9%A3%9F%E5%93%81%E5%8F%8A%E9%A3%B2%E5%93%81/%E6%B1%BD%E6%B0%B4/c/04010200\"     # 汽水\n",
        "    current_time_str = datetime.datetime.now().strftime(\"%Y_%m_%d\")    # today's date > datetime obj > str\n",
        "    df = crawler(url)       # crawler() function will return a dataframe\n",
        "    print(df)\n",
        "    df.to_csv(current_time_str + \"_demo.csv\", encoding=\"UTF-8\")     # save dataframe as csv file\n"
      ],
      "metadata": {
        "id": "C3wIQkParIwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jTwHOyU6mfV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome"
      ],
      "metadata": {
        "id": "1Gz_jdvCmjvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Wellcome web crawler\n",
        "\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "current_page= 1\n",
        "url = \"https://www.wellcome.com.hk/zh-hant/category/100002/\"+ str(current_page) +\".html\"\n",
        "\n",
        "try:\n",
        "    driver.get(url)\n",
        "except:\n",
        "    print('url not found')\n",
        "    exit\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "remark=[]\n",
        "name = []\n",
        "selling_price=[]\n",
        "original_price=[]\n",
        "link=[]\n",
        "selling_price_base=[]\n",
        "\n",
        "df_dict={\n",
        "    \"name\" : name,\n",
        "    \"selling_price\" : selling_price,\n",
        "    \"original_price\" : original_price,\n",
        "    \"remark\" : remark,\n",
        "    \"link\" : link\n",
        "}\n",
        "\n",
        "\n",
        "total_page = driver.find_element(By.XPATH,'//a[@class=\"last cursor num-box\"]')\n",
        "total_page = int(total_page.text)\n",
        "#print('total page : ', total_page)\n",
        "\n",
        "\n",
        "while total_page >= current_page:\n",
        "    url = \"https://www.wellcome.com.hk/zh-hant/category/100002/\"+ str(current_page) +\".html\"\n",
        "    try:\n",
        "        driver.get(url)\n",
        "\n",
        "        products = driver.find_elements(By.XPATH,'//a[@class=\"a-link router-link ware-wrapper\"] ')\n",
        "        for product in products:\n",
        "        # name= product.find_elements(By.XPATH, './/div[contains(@class, \"name\")]')[0].text\n",
        "        # print(name)\n",
        "\n",
        "        # print(product.text.split('\\n'))\n",
        "\n",
        "            try:\n",
        "                remark.append(product.find_elements(By.XPATH, './/div[contains(@class, \"pro tag\")]')[0].text)\n",
        "            except:\n",
        "                remark.append(None)\n",
        "\n",
        "            try:\n",
        "                name.append(product.find_elements(By.XPATH, './/div[contains(@class, \"name\")]')[0].text)\n",
        "            except:\n",
        "                name.append(None)\n",
        "\n",
        "            try:\n",
        "                price_base = product.find_elements(By.XPATH, './/div[contains(@class, \"price\")]')[0].text.split(\"\\n\")[0]\n",
        "                small_base = product.find_elements(By.XPATH, './/div[contains(@class, \"price\")]')[0].text.split(\"\\n\")[1]\n",
        "                total=price_base+small_base\n",
        "                selling_price.append(total)\n",
        "\n",
        "            except Exception as error:\n",
        "                selling_price.append(None)\n",
        "            try:\n",
        "                original_price.append(product.find_elements(By.XPATH, './/span[contains(@class, \"line-price\")]')[0].text)\n",
        "            except:\n",
        "                original_price.append(None)\n",
        "\n",
        "        product_link =driver.find_elements(By.XPATH, './/a[contains(@class, \"a-link router-link ware-wrapper\")]')\n",
        "        for product in product_link:\n",
        "            link.append(product.get_attribute('href'))\n",
        "\n",
        "        current_page = current_page+1\n",
        "    except:\n",
        "        print('url not found')\n",
        "        exit\n",
        "\n",
        "df = pd.DataFrame(df_dict)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    current_time_str = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "    print(df)\n",
        "    df.to_csv(current_time_str + \"_wellcome.csv\", encoding=\"UTF-8\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UKVJ6wRhBk-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ztore\n"
      ],
      "metadata": {
        "id": "svmsOPxAQ1I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ztore\n",
        "\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def ztore_crawler(url):\n",
        "\n",
        "    driver = webdriver.Chrome() # create instance of selenium driver\n",
        "\n",
        "    try:\n",
        "        driver.get(url)\n",
        "    except:\n",
        "        print('url not found')\n",
        "        exit\n",
        "\n",
        "\n",
        "    result01 = driver.find_element(By.XPATH, '//*[@id=\"BaseLayout\"]/div/div[4]/div[2]/div')\n",
        "    print(result01.text)\n",
        "\n",
        "    #Number of product\n",
        "    reult02 = driver.find_element(By.XPATH, '//*[@id=\"BaseLayout\"]/div/div[4]/div[1]/div[1]/div[2]/div/div/div[1]/span/span')\n",
        "    reult02 = reult02.text\n",
        "    print('reult02 : ', reult02)\n",
        "\n",
        "    #Click button for show all\n",
        "    send_button = driver.find_element(By.XPATH, '//*[@id=\"BaseLayout\"]/div/div[4]/span/div/span')\n",
        "    send_button.click()\n",
        "\n",
        "\n",
        "    time.sleep(3)\n",
        "\n",
        "\n",
        "    remark=[]\n",
        "    name = []\n",
        "    selling_price=[]\n",
        "    original_price=[]\n",
        "    link=[]\n",
        "    selling_price_base=[]\n",
        "\n",
        "\n",
        "    result_dict={\n",
        "        \"name\" : name,\n",
        "        \"selling_price\" : selling_price,\n",
        "        \"original_price\" : original_price,\n",
        "        \"remark\" : remark,\n",
        "        \"link\" : link\n",
        "    }\n",
        "\n",
        "    for product in result01:\n",
        "        try:\n",
        "            remark.append(product.find_elements(By.XPATH, './/div[contains(@class, \"jsx-845759319 label-text\")]')[0].text)\n",
        "        except:\n",
        "            remark.append(None)\n",
        "        try:\n",
        "            name.append(product.find_elements(By.XPATH, './/div[contains(@class, \"jsx-2940394913 jsx-676457135\")]')[0].text)\n",
        "        except:\n",
        "            name.append(None)\n",
        "        try:\n",
        "            price_base = product.find_elements(By.XPATH, './/div[contains(@class, \"jsx-2940394913 jsx-676457135 promotion\")]')[0].text.split(\"\\n\")[0]\n",
        "            selling_price.append(None)\n",
        "\n",
        "        except Exception as error:\n",
        "            selling_price.append(None)\n",
        "        try:\n",
        "            original_price.append(product.find_elements(By.XPATH, './/span[contains(@class, \"jsx-1595401699 PerCountLabel\")]')[0].text)\n",
        "        except:\n",
        "            original_price.append(None)\n",
        "\n",
        "        product_link =driver.find_elements(By.XPATH, './/a[contains(@class, \"jsx-2940394913 jsx-676457135 ProductItem  windowing-layout\")]')\n",
        "        for product in product_link:\n",
        "            link.append(product.get_attribute('href'))\n",
        "\n",
        "    driver.quit()\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "\n",
        "ztore_url = {\"case_offer\":\"https://www.ztore.com/tc/category/all/beverage/case-offers\",\n",
        "             \"recommended_drinks\":\"https://www.ztore.com/tc/category/all/beverage/recommended-drinks\",\n",
        "             \"lemon_tea\":\"https://www.ztore.com/tc/category/all/beverage/rtd--tea-lemon-tea\",\n",
        "             \"coffee_milk_tea\":\"https://www.ztore.com/tc/category/all/beverage/rtd-coffee-milk-tea\",\n",
        "             \"beverage\":\"https://www.ztore.com/tc/category/all/beverage/carbonated-beverage\",\n",
        "             \"water\":\"https://www.ztore.com/tc/category/all/beverage/water\",\n",
        "             \"juice_energy_drink\":\"https://www.ztore.com/tc/category/all/beverage/juice-and-energy-drink\",\n",
        "             \"healthy_drinks\":\"https://www.ztore.com/tc/category/all/beverage/healthy-drinks\",\n",
        "             \"plant_based_milk\":\"https://www.ztore.com/tc/category/all/beverage/soy-plant-based-milk\",\n",
        "             \"long_life_milk\":\"https://www.ztore.com/tc/category/all/beverage/long-life-milk-soy\",\n",
        "             \"coffee_tea\":\"https://www.ztore.com/tc/category/all/beverage/coffee-tea\",\n",
        "             \"energy_drink\":\"https://www.ztore.com/tc/category/all/beverage/energy-drink\"\n",
        "             }\n",
        "\n",
        "if __name__ == '__main__':          #print csvfile\n",
        "    for k, v in ztore_url.items():\n",
        "        current_time_str = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "\n",
        "        df = pd.DataFrame(ztore_crawler(v))\n",
        "        df.to_csv(k +  \"_\" + current_time_str + \"ztore.csv\", encoding=\"UTF-8\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yC8LN8PDB06g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}